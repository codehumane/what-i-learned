# Monolith to Microservices

1, 2장 읽었는데 생각보다 재밌음. 기록도 같이 하기로.

# CH3. Splitting the Monolith

- 앞서 MSA가 좋을지 안 좋을지 고민했음.
- 만약, 좋은 경우라면 어떻게 시작해야 할까?

## To Change the Monolith, or Not?

- 가장 먼저 생각해 볼 것 중 하나가 현재 모놀리스를 바꿀지 말지.
- 현재 모놀리스 수정이 가능하다면 유연하게 계획 세울 수 있음.
- 하지만 그렇지 않을 수도 있으며 다양한 예시를 소개.
- 그리고 이 때의 대응법들을 하나씩 설명.

### Cut, Copy, or Reimplement?

- 초기에는 모놀리스로부터 코드를 복제하는 게 좋음.
- 즉, 모놀리스에는 코드를 남겨놓는 게 좋음.
- 일정 기간 우리에게 더 많은 선택지를 제공하기 때문.
- 롤백을 할 수도 있고, 2개 기능을 병렬로 실행할 수도 있음.
- 마이그레이션이 성공이면 그 때 모놀리스에서 코드를 제거.

### Refactoring the Monolith

- 기존의 모놀리스는 보통 기술 레이어로 구조화되어 있음.
- 도메인에 맞춰 구조화되어 있지 않으며, 이는 MSA화의 일반적 어려움.
- Working Effectively with Legacy Code 책에 나왔던 것처럼,
- 접합부<sup>seam</sup>를 찾고 새로운 구현체를 만들고 교체하기를 권장.
- 이는 바운디드 컨텍스트와도 매우 잘 맞음.

#### A modular monolith?

- 모놀리스의 접합부들을 새로운 모듈로 나눠갈 수 있음.
- 여전히 한 단위로 배포하지만, 여러 모듈이 정적으로 연결된 구성.
- 시스템 분리에 비해 모듈 분리는 좀 더 가역적 결정.

#### Incremental rewrites

- 저자는 일단 기존 코드베이스를 구조화하는 것을 먼저 시도.
- 때로는 이 작업을 통해 마이크로서비스가 필요 없음을 깨닫기도.
- 하지만 보통은 새로운 시스템을 바로 분리하는 경우를 더 많이 만남.
- 만약, 며칠에서 몇 주의 작업이라면 기존 코드 구조화를 먼저 시도.
- 몇 달이 걸리는 일이라면 저자의 접근법을 재검토.

## Migration Patterns

> 각 패턴의 장단점을 이해할 것. 이들이 모든 상황에 적절한 건 아님.

- 마이그레이션을 위한 여러 패턴들을 이제 살펴볼 것.
- 특별한 건 없을 듯 해서 간단히만 기록.

## Pattern: Strangler Fig Application

- [Strangler Fig Application](https://martinfowler.com/bliki/StranglerFigApplication.html).
- 필요시 변경을 빠르고 쉽게 돌릴 수 있는 게 장점.
- 기존 시스템을 건드리지 않으므로, 모놀리스의 경합으로부터 자유로운 것도 장점.
- 프록시 도입 시 여러 팀이 공유하고 같이 수정해야 한다면 이 또한 경합이므로 주의.
- 공유 미들웨어 계층의 기능 수는 가급적 줄여야 함.
- 큐를 수신하는 경우엔, 기존 대기열을 먼저 수신하는 컨텐츠 기반 라우터를 먼저 추가하고, 여기서 컨텐트에 따라 모놀리스와 신규 서비스의 대기열로 분류해서 메시지를 전달하기도.

## Changing Behavior While Migrating Functionality

- 계속 점진적 마이그레이션을 얘기하는 이유 중 하나는,
- 마이그레이션과 피처 개발을 적절히 섞을 수 있기 때문.
- 그러나, 마이그레이션 중인 기능의 변경은 어려움.
- 예컨대, 신규 서비스로 추출한 기능에 대해 몇 가지 버그 픽스나 기능 변경을 추가.
- 이 경우 과거 모놀리스로 호출을 돌리면 이 변경들이 사라짐.
- 마이그레이션 중인 기능의 변경은 어려움을 받아들여야 함.
- 마이그레이션 단위를 매우 작게 쪼개면,
- 마이그레이션 동안의 기능 변경은 허용하지 않기 쉬워지고,
- 따라서 이 어려움을 최소화할 순 있음.

## Pattern: UI Composition

- UI에서의 마이그레이션.
- 가디언지의 온라인 CMS를 개편할 일이 있었음.
- 점진적 마이그레이션을 선호했기에 수직 분할로 교체.
- 여행, 뉴스, 문화, ... 식으로.
- 그리고 그 안에서도 더 나눌 건 없을지 계속 탐색.
- 2가지 구성 기법이 유용했음.
- 페이지 컴포지션과 위젯 컴포지션.
- 내용은 특별한 게 없어 생략.
- 모바일 UI 얘기도 나옴.
- 앱은 웹과 달리 릴리즈를 위해 제출과 심사가 필요.
- 그래서 앱 배포 없이, 서버 쪽에서 변경을 배포하면, 앱에서 동적으로 신규 기능을 쓸 수 있게끔.

## Pattern: Branch by Abstraction

- strangler fig를 위해선 시스템 경계부 호출을 가로채야 함.
- 하지만, 기존 시스템의 깊은 부분을 추출하려면 기존 코드를 수정해야 함.
- 별도 브랜치(그리고 브랜치 수명은 보통 길기 마련)에서 이 변경을 수행하면 병합 시 고통.
- 점진적으로 코드베이스를 변경하면서도, 코드를 공유하는 다른 개발자에게 덜 영향을 미쳐야 함.
- branch by abstraction.

### How It Works

- 흔히 보는 방식이라 기록은 간단히만.
- 1단계: 추상화 생성
- 2단계: 추상화 사용
- 3단계: 새로운 구현 추가
- 4단계: 구현 전환
- 5단계: 기존 구현과 추상화 제거

### As a Fallback Mechanism

- 4단계 후 만약 신규 구현 호출이 실패하면,
- 기존 구현을 폴백으로 호출하는 것.

## Pattern: Parallel Run

- 과거와 신규 구현 모두를 호출하고, 결과를 비교하는 것.
- 기능적인 검증뿐만 아니라, 실패율이나 지연 시간 등 비기능적 요구사항 검증까지.
- 가장 먼저 소개하는 사례는 가격 책정 시스템.
- 과거 서비스를 호출하면 과거 디비에 데이터가 쌓이고,
- 동시에 신규 서비스 호출하면 신규 디비에 데이터가 쌓이며,
- 적절한 주기로 두 디비 데이터를 비교해 검증.
- 스파이 사용도 얘기.
- 알림 서비스를 예로 설명.
  - 신규 서비스 추출 후 병행 실행.
  - 이 때, 메일 발송이 두 번 일어나면 안 됨.
  - 따라서, 신규 서비스에서는 스파이를 적용.
  - 발송 호출 받으면 메일 발송 대신 기록만 남기고 끝나는 것.
  - 이 기록은 나중에 확인이나 검증을 위해 활용.
  - 문제 없으면 스파이를 실제 구현으로 대체.
- 카나리 릴리즈와 다크 런칭 얘기도.
- 병행 실행은 카나리가 아니라 다크 런칭의 한 구체화라는.

## Pattern: Decorating Collaborator

- 잘 사용되지는 않아 보임.
- 기존 구현을 고치지 못하는 경우 데코레이터 패턴 활용.
- 여기서는 프록시를 추가하고, 프록시에서 과거 버전과 신규 버전으로의 호출을 적절히 제어하는 것.
- 저자가 경계하는 미들웨어가 똑똑해지는(비대해지는) 문제가 있음.
- 더불어, 프록시에서는 내부 데이터를 잘 알지 못하기에, 신규 서비스 호출을 위한 추가 데이터를 과거 시스템에 질의해야 할 수도(이는 신규 기능 개발이 필요할 수도).

## Pattern: Change Data Capture

- 이 역시 경계해야 할 방법.
- 디비 트리거나, 디비 트랜잭션 로그를 활용.
- 변경을 감지하고 적절한 신규 서비스로 이를 알려주기.
- 데이터를 주기적으로 질의해서 알려줄 수도 있음(batch delta copier).
- 하지만 디비 스키마 등의 제약에 의해 중요한 변경이 유실될 수도.

# CH4. Decomposing the Database

- 마이크로서비스는 정보 은닉 위에 잘 동작함.
- 결국 데이터 저장소와 검색 메커니즘의 캡슐화 필요.
- 데이터도 함께 분리해야 함.
- 하지만 어려움.
- 데이터 전환 중 동기화, 트랜잭션 무결성, 논리적/물리적 스키마 분해, 조인, 지연, ...

## Pattern: The Shared Database

- 커플링을 3개로 나눠 생각할 수 있음.
- 도메인 커플링, 일시적 커플링, 구현 커플링.
- 데이터베이스를 다룰 땐 보통 구현 커플링.
- 서비스들이 동일 데이터베이스를 공유하기 때문.
- 변경 영향이 큼. 즉, 느리고 위험.

### Coping Patterns

- 일단, 각 서비스가 각자의 데이터를 소유하는 게 제일 좋음.
- 불가하다면, 뒤에서 다룰 뷰 패턴을 고려(물론 좋지 않음).
- 또는, 데이터베이스 래핑 서비스 패턴 사용(권장 X).

### Where to Use It

- 저자 생각에는 2가지 경우에 적절.
- 하나는 읽기 전용 정적 참조 데이터인 경우.
- 예컨대 각 나라의 환율 코드 정보, 우편 번호.
- 잘 바뀌지 않으며 어드민 작업으로 변경 관리.
- 나머지 하나는, 데이터베이스를 의도적으로 엔드포인트로 노출한 경우.
- 서비스 인터페이스로서의 데이터베이스 패턴에서 다룰 예정.

## But It Can't Be Done!

- 모놀리스 분리 초기엔 스키마를 독립적으로 구성하긴 어려울 수도.
- 시간도 오래 걸리고, 시스템의 민감한 부분을 변경해야 할 수도.
- 이 때는 일단 더 나빠지는 것은 막고 점진적으로 나아가기.
- 참고로, 데이터베이스와 스키마 용어 혼동 주의.
- 책에서는 데이터베이스를 논리적으로 격리된 스키마로 사용.

## Pattern: Database View

- 뷰를 이용하면 서비스 별로 스키마를 제한적으로 제공.
- 정보 은닉을 위함.
- 예컨대, 고객ID/주소/암호/멤버십카드번호 컬럼으로 이뤄진 모놀리스 테이블이 있음.
- 여기서 고객ID/멤버십카드번호 컬럼만으로 뷰를 구성하고 멤버십 서비스에겐 이 매핑 정보만 제공.
- 하지만, NoSQL에서는 뷰 기능을 지원하지 않는 게 대다수.
- 그리고 materialized view는 성능은 빠르나 캐시이므로 stale 데이터 문제 가짐.
- 무엇보다 뷰는 읽기 전용.
- 소유권도 문제인데, 공개된 뷰는 서비스 인터페이스와 유사하니, 원천 스키마를 다루는 곳에서 데이터 관리를 권장.
- 스키마 분해가 실용적이지 않을 때 뷰를 첫 단계로 시작하기엔 괜찮음.

## Pattern: Database Wrapping Service

- A, B, C 서비스가 공통 데이터베이스 스키마를 직접 참조하는 상황.
- 데이터베이스를 접근하는 D 서비스를 만들고, A~C가 데이터 접근/조작이 필요할 땐 D를 거치는 것.
- 이 역시 더 나빠지는 것을 돕는 수단 중 하나.
- 또한 스키마가 나의 소유가 아님을 명시화하는 효과도.
- 뷰에 비해 제약이 적은 것도 장점.

## Pattern: Database-as-a-Service Interface

- 때로는 클라이언트가 직접 데이터베이스에 질의하고 싶을 수 있음.
- 대량의 데이터를 조회해야 한다거나, Tableau 같은 SQL 엔드포인트를 필요로 하는 도구를 사용한다거나.
- 하지만, 서비스 경계 내에서 우리가 사용할 데이터베이스와 외부에 노출시킬 것은 구분해야 함.
- 한 가지 방법은 읽기 전용의 공개를 염두하고 설계한 전용 데이터베이스를 만들기.
- 이벤트 스트림이나 동기식 API를 제공하는 것과 어떤 측면에서는 비슷.
- 마틴 파울러의 [Reporting Database](https://martinfowler.com/bliki/ReportingDatabase.html)도 하나의 사례.
- 내부 데이터베이스 변경이 공개된 데이터베이스에 반영되는 시점은 다양.
- 아예 변경을 반영 안 할 수도.
- 따라서 클라이언트들은 데이터가 일관성을 보장하지 않음을 전제해야.
- 공개 데이터에비으소 변경 반영을 위해서는, [CDC](https://en.wikipedia.org/wiki/Change_data_capture)나 배치 프로세스 또는 이벤트 처리를 활용.
- 참고로 저자는 배치 프로세스가 잘 안 돌거나 오래 걸려서 문제가 된 경우가 많았다고.
- 뷰에 비해서는 유연하고 정교하지만, 추가 개발과 데이터베이스 관리 비용이 발생.

## Transferring Ownership

- 지금까지는 근본적 문제 해결이 아니라 임시 방편들 얘기.
- 애그리거트 관련 로직을 캡슐화하는 게 마이크로서비스라면,
- 결국 애그리거트의 상태나 관련 데이터도 서비스 소유 스키마로 이동해야 함.
- 그리고 다른 서비스가 이 데이터를 필요로 한다면 잘 정의된 인터페이스로 제공해야 함.

### Pattern: Aggregate Exposing Monolith

- 특별한 내용은 아님.
- 송장 서비스에서 승인을 위해 직원 정보 필요.
- 이 데이터는 모놀리스에 있음.
- 그럼 모놀리스에 서비스 엔드포인트(API, 이벤트 스트림 등) 추가.
- 송장 서비스가 필요로 하는 것을 명시화 하는 것.
- 이 때도 모놀리스가 단순한 데이터베이스 래퍼가 되면 안 됨.
- 여전히 모놀리스가 무엇을 노출하고 말지를 잘 관리해야 함.
- 이런 일련의 과정에서 다음으로 추출할 후보가 보이기도 함.
- 여기서는 직원 서비스.
- 데이터베이스 뷰를 제공하는 것에 비해 작업량은 더 들지만 장기적으로 이득.
- 뷰 제공은 모놀리스를 건드릴 수 없는 경우의 접근법으로 제한.
- 물론 이 때는 CDC, 데이터베이스 래핑 서비스 패턴도 함께 고려.

### Pattern: Change Data Ownership

- 이건 위와 반대로, 송장 서비스로 송장 관련 데이터들을 함께 추출하는 것.
- 이건 상대적으로 더 어려움.
- 외부 키 제약, 트랜잭션 경계 달라짐 등 때문.
- 이 어려움들은 뒤에서 다시 다룰 예정.

## Data Synchronization

- strangler fig 패턴의 장점은, 신규 서비스 사용 중 문제가 생기면 과거 서비스로 전환할 수 있다는 점.
- 하지만 이를 위해서는 서비스 간 데이터 동기화 문제를 함께 고려해야 함.
- 일단 얼마나 일관성 있어야 하는지를 먼저 결정.
- 만약 완전히 일관성 있어야 한다면 데이터를 한 곳에서 관리해야 함.
- 예컨대 모놀리스 데이터베이스 하나를 사용하고 신규 서비스에는 뷰를 통해 데이터 읽기.
- 그리고 이관이 성공적이라 판단되면 그 때 데이터도 이관.
- 하지만 공유 디비의 위험성은 매우 크니 일시적으로만 사용.
- 한편 코드와 데이터를 한 번에 이관해야 한다면(가능한 피해야겠지만),
- 신규 서비스로 스위칭하기에 앞서 데이터를 일괄로 복제해 갈 수 있음.
- 그러나 과거 서비스로 롤백할 경우 그 동안 생긴 변경은 과거 서비스엔 없음.
- 마지막으로 양 서비스 간 데이터 동기화 방법도 있으나 이는 매우 고려할 게 많음.

## Pattern: Synchronize Data in Application

- MySQL 데이터베이스에 있던 것을 Riak으로 옮겨야 했음.
- 데이터베이스가 오프라인일 수 있는 시간은 한정적.
- 당연히 데이터 유실은 없어야 함.
- 빠른 롤백도 가능해야 했음.
- 처음엔 MySQL이 SSOT였고,
- Riak에 계속 동기화 됐으며,
- 일정 시간 이후엔 Riak이 SSOT가 되고,
- MySQL은 차차 제거.
- 이 과정을 이제 세부적으로 설명.

### Step 1: Bulk Synchronize Data

- 첫 번째 단계는 새로운 데이터베이스에 데이터를 복제.
- 위 사례에서는 배치 가져오기를 수행.
- 이 때의 문제는 과거 데이터베이스에 계속 새로운 변경들이 일어나는 것.
- 그렇다고 과거 시스템을 오프라인으로 둘 수도 없는 일.
- 그래서 가져오기 완료 후 CDC 프로세스를 함께 사용.

### Step 2: Synchronize on Write, Read from Old Schema

- 데이터베이스가 계속 동기화 되는 상태에서 새로운 애플리케이션을 배포.
- 이 애플리케이션은 신규와 과거 데이터베이스 양쪽으로 쓰기를 수행.
- 이 단계에서의 목표는, 2개의 원천에 데이터를 올바르게 작성하는지 확인하고, Riak이 예상대로 동작하는지 검증하는 것.
- 읽기는 여전히 MySQL을 통해 하므로 Riak에 문제가 생겨도 영향 없게 함.

### Step 3: Synchronize on Write, Read from New Schema

- 이제 Riak을 통한 데이터 읽기를 검증할 단계.
- Riak을 SSOT로 두기.
- 쓰기는 여전히 양쪽 데이터베이스로 함.
- 그래야 문제가 있을 경우 폴백 가능.
- 문제가 없다면 과거 스키마는 제거.

### Where to Use This Pattern

- 애플리케이션 코드 분리에 앞서 스키마 분리를 먼저 진행할 때도 유용.
- 롤백 시나리오에서도 유리.

### Where to Use It

- 모놀리스와 신규 서비스 모두가 양쪽 디비 동기화를 신경 쓰는 상황을 생각해보자.
- 이는 매우 복잡한 일이고, 한 쪽이라도 잘못된 쓰기를 한다면 문제가 됨.
- 스위치 상태(누가 active인지)를 알 수 있다면 이 위험은 많이 줄어듦.
- 하지만 카나리 배포 등으로 누구를 호출하는지 확인이 어렵다면 문제가 클 수도.
- 개인적으로는 이 방법은 상대적으로 별로라 생각.

## Pattern: Tracer Write

- 일단, 현재 시스템은 자신의 데이터를 계속 유지.
- 동시에, 변경 사항들을 신규 서비스에도 인터페이스를 통해 전달.
- 기존 코드는 점차 신규 서비스에서 데이터를 얻어오는 것으로 바뀜.
- 모든 게 바뀌면 기존 데이터베이스는 종료.
- SSOT 추구는 지극이 합리적 욕구.
- 하지만 이를 위해서는 서비스 추출 시 큰 전환이 필요함.
- 이는 잘못될 위험이 큼.
- tracer 패턴은 점진적 변경을 꾀하고 위험을 최소화.
- 송장 서비스에 관련된 데이터가 3가지라고 가정.
- 처음엔 1개 데이터를 모놀리스와 신규 서비스 양쪽에 쓰기.
- 잘 된다면 이제 모놀리스는 신규 서비스로 읽기도 요청.
- 나머지 2개 데이터에 대해서도 마찬가지로 진행.

### Data Synchronization

- 데이터 중복 시 항상 따라다니는 건 일관성 문제.
- tracer write 패턴에서도 마찬가지.
- 해결을 위한 3가지 방법 존재.
  - 1: write to one source: 모든 쓰기를 1개의 원천에 보내기. 쓰기 이후에 다른 원천으로 데이터 동기화.
  - 2: send writes to both sources: 양쪽에 쓰기 요청 보내기. 클라이언트가 직접하든, 중재자를 두든.
  - 3: send writes to either source: 둘 중 하나의 원천에 보내고, 뒤에서는 양방향 동기화.
- 양방향 동기화는 달성이 어려우므로 3번 선택지는 피해야 함.
- 모든 선택지에는 일관성을 위한 지연이 존재.
- 매일 1번 일괄 동기화를 한다면 최대 1일의 비일관성 발생.
- CDC를 이용한다면 몇 초 이내.
- 물론 결과적 일관성을 제공하긴 함.
- 자신의 상황에 맞는 결정과 도구 활용 필요.

### Example: Orders at Square

- 테이크아웃 음식 배달을 위한 주문 도메인 얘기.
- 구매자, 식당, 배달기사 이렇게 서로 다른 이해관계자가 주문이라는 같은 개념에 엮임.
- Square는 주문을 잘 쪼개서, 서로 다른 유스케이스들의 변경이 독립적으로 일어나길 원함.

#### Creating the new service

- 첫 번째 단계는 `Fulfillments(주문처리)` 서비스 생성.
- 이는 식당과 배달기사와 관련된 주문 데이터 관리.
- 나중엔 신규 서비스가 SSOT가 될 것.
- 처음엔 기존 시스템에 백그라운드 워커를 두고, `주문처리` 데이터가 생기면 이를 신규 서비스로 동기화.
- 이 동기화 작업은 데이터베이스 직접 삽입이 아니고, 신규 서비스가 제공하는 API를 이용.
- 백그라운드 작업은 피처 플래그로 활성 여부를 제어함.
- 문제가 있으면 언제든 끄기 위함.
- 한동안 제대로 동작하는지 검증 후 피처 플래그는 제거.

#### Synchronizing the data

- 이 방식의 문제 중 하나는 동기화가 단방향이라는 것.
- 그래서 Square는 모든 업데이트를 양쪽 시스템에 보냄.
- tracer write 패턴 소개처럼 말이다.
- 다만, 업스트림 클라이언트가 챙겨야 하는 에러 조건도 복잡해짐(한 서비스만 성공할 수도).
- 또한, 이렇게 되면 데이터가 원자성을 지키지 못함.
- 따라서 한 쪽에서만 데이터가 보일 수도.
- 뒤에서 결과적 일관성 다룰 때 다시 얘기.
- 위 사례의 유스케이스는 다행히 일시적 비일관성이 문제되지는 않았음.
- 마지막으로 잠시 회고하며, `주문처리` 전달이 API 대신 이벤트 처리 방식이었으면 어땠을까 하는 얘기도 나옴.

#### Migrating consumers

- 이제 Fulfillments 서비스는 필요한 정보를 다 아는 상태.
- 신규 서비스 사용하도록 스위치만 키면 됨.
- 이런 점진적 방법(데이터 마이그레이션, 컨슈머 변경)은 매우 효과적이었다고 함.
- 컨슈머들의 변경은 작은 릴리즈 중 하나였다고.
- 필요하다면 Fulfilments를 더 작은 단위로 나누는 것도 가능.
- 중복된 데이터의 유지는 동기화 부담이 있긴 하지만 폴백 때문에 안전.

### Where to Use It

- 데이터 동기화가 가장 어려움.
- 양방향 동기화를 피할 수 있다면 다른 선택지들은 상대적으로 단순.
- 혹은 이벤트 주도 시스템이나 CDC 파이프라인이 이미 있다면 동기화 어려움도 좀 더 쉽게 극복.
- 비일관성을 얼마나 허용할 수 있는지도 중요한 고려 요소.

## Splitting Apart the Database

- 이제부터 저자가 권장하는 방식.
- 데이터베이스도 경계를 찾아 쪼개야 함.
- 일단 먼저 논리적 분리와 물리적 배포가 어떤 연관이 있는지 알아야 함.

### Physical Versus Logical Database Separation

- 데이터베이스 분할 시 논리적 분리를 먼저 시도해야 함.
- 단일 데이터베이스 엔진은 2개 이상의 구분된 스키마를 호스팅할 수 있음.
- 한편, 엔진 별로 논리적 스키마도 1개씩 둘 수도.
- 논리적 구분은 독립적 변경과 데이터 은닉을 가능케 함.
- 물리적 구분은 시스템의 강건성을 높이고 리소스 경합을 줄여 성능과 지연에 유리.
- 논리적 구분만 한다면 SPOF를 가지는 것.
- 물론, 데이터베이스 엔진들은 multi-primary 모드나 warm 페일오버 등 SPOF를 피하는 다양한 도구들 지원.
- 그리고 여러 클러스터를 갖는 것은 여러 비용을 수반.
- 논리적 구분만 할 때는 데이터베이스 뷰도 공유할 수 있음.

## Splitting the Database First, or the Code?

- 애플리케이션 코드와 데이터베이스 모두 분리되어야 완료.
- 이를 위한 순서로 3가지 선택지 있음.
- 첫째는 데이터베이스 먼저 그리고 코드.
- 둘째는 코드 먼저 그리고 데이터베이스.
- 셋째는 둘 다 한 번에.

### Split the Database First

- 스키마를 먼저 분리하면 하나의 동작을 위한 데이터베이스 호출이 늘어남.
- select 하나가, 2개의 원천에 대한 select 후 메모리 조인으로 바뀔 수도.
- 트랜잭션 무결성도 깨짐.
- 이 문제들은 뒤에서 해결책을 다룰 예정.
- 데이터를 먼저 분리하면, 컨슈머들에게 이관이나 롤백의 영향을 안 끼침.
- 하지만 코드 배포는 여전히 모놀리스이니 한동안은 여전히 이득이 적음.
- 공유 데이터베이스의 고통은 시간이 지날수록 느껴지는 것이며 단기적으로는 이점을 느끼기 어려움.
- 따라서 데이터베이스 분리에 따른 성능이나 데이터 일관성 이슈가 크게 걱정될 때 활용.

#### Pattern: Repository per bounded context

- 하나의 리포지토리 계층이 아니라, 바운디드 컨텍스트 별로 리포지토리들을 두라는 것.
- 바운디드 컨텍스트가 어떤 테이블들에 접근하는지 잘 보이므로 분리를 계획하는데 도움.
- 다만, 외부 키 제약 등 모든 게 드러나는 건 아님에 유의.
- SchemaSpy 같은 도구를 함께 사용하면 도움이 됨.

#### Pattern: Database per bounded context

- 위 접근법을 스키마 단위로 확장.
- 코드 분리에 앞서 스키마 분리도 먼저 해볼 수 있음.
- 쏘트웍스에서 회사의 수익을 계산하고 예상하는 메커니즘을 구현해야 했음.
- 3가지 구분된 바운디드 컨텍스트가 드러났으나, 팀이 3명이어서 각각을 개별 서비스로 만들기는 비용 손해.
- 그래서 바운디드 컨텍스트를 각 모듈로 격리하고 하나의 서비스로 배포되게 함.
- 각 바운디드 컨텍스트는 독립된 데이터베이스를 가짐.
- 나중에 마이크로서비스로 분리를 고려한 선택.
- 그러나, 이 미래는 결국 오지 않았음.

### Split the Code First

- 보통은 애플리케이션 먼저 분할.
- 일단 분리하고 나면 새로운 서비스가 어떤 데이터를 사용하는지 더 쉽게 이해할 수 있음.
- 코드의 독립적 배포도 상대적으로 빠르게 얻을 수 있음.
- 유일하게 이 접근법에서 걱정하는 건, 공유 데이터베이스가 계속 남는 것.
- 스스로 솔직하게 묻기: 애플리케이션 분리 후 데이터베이스 역시 분할할 자신이 있는가.

#### Pattern: Monolith as data access layer

- 새로운 서비스가 모놀리스 데이터를 필요로 할 땐,
- 모놀리스에 엔드포인트를 추가하고 신규 서비스는 이를 통해서 데이터 접근.
- 여러 장점이 있는 것에 비해 잘 쓰이지 않는 것에 저자는 놀랐다고 함.
- 아마도 모놀리스를 죽은 것으로 간주하고 멀리 벗어나고 싶기 때문일 것이라 추측.
- 하지만, 데이터 분해를 실행하지 않은 상태에서도, 정보 은닉을 할 수 있고, 새로운 서비스를 모놀리스로부터 격리된 상태로 유지할 수 있음.
- 그리고 이 때 생기는 API는 새로운 서비스 추출 후보가 됨.

#### Pattern: Multischema storage

- 송장 서비스의 핵심 데이터들이 여전히 모놀리스에 남아 있더라도,
- 송장 리뷰에 대한 기능이 추가될 때는 리뷰 데이터를 신규 스키마에서 관리.
- 모놀리스 데이터베이스에서 데이터를 추출하는 데에는 시간이 걸림.
- 하나씩 옮겨오는 과정에서 동시에 2개 스키마를 다뤄야 할 수도 있음.

### Split Database and Code Together

- 물론, 데이터와 코드를 함께 옮길 수도 있음.
- 하지만 변경 단위가 너무 큼.
- 결정의 영향을 파악하는 데 더 오랜 시간 걸릴 수도.
- 이 방법은 권장하지 않음.

### So, Which Should I Split First?

- 처한 상황이 각자 다르기에, "상황에 따라 다름"을 많이 얘기.
- 그래서 여러 맥락과 장단점 충분히 소개.
- 하지만, 아래와 같은 방식을 저자는 선호.
- 스키마를 먼저 분리.
- 그렇지 않으면 코드 먼저 분리하고, 이로 인한 데이터 소유권 영향을 살핌.

## Schema Separation Examples

- 스키마 분리에 대해 높은 추상화 수준으로 살펴봄.
- 하지만, 실제 데이터베이스 분해는 많은 어려움이 있음.
- 저수준에서 데이터 분해 패턴과 영향을 살펴볼 예정.

## Pattern: Split Table

- 때로는 1개 테이블에 여러 서비스로 분해할 데이터가 담기기도.
- 사례에서는 아래 테이블.

| SKU | Item | Stock level |
| -- | -- | -- |
| 1 | 아이템1 | 774 |
| 2 | 아이템2 | 16 |

- SKU, Item 조합은 카탈로그 서비스로 이동.
- SKU, Stock level 조합은 재고 서비스로 이동.
- 하지만 1개 테이블에 모두 들어 있음.
- 점진적으로 한다면, 일단 같은 스키마에서 테이블만 먼저 분리.
- 이 때 외부키를 둘 수도 있으나, 결국 분리할 것을 생각하면 큰 효과는 없음.
- 방금 사례는 간단한 편.
- 하지만 아래 같은 경우는 어떨까.

| ID | Name | Status |
| -- | -- | -- |
| 1 | Alice | VERIFIED |
| 2 | Bob | SUSPENDED |

- 고객 관리 서비스와 재정 서비스가 1개의 컬럼인 Status를 업데이트 하는 경우임.
- 가입 시에는 이메일 인증을 통해 NOT_VERIFIED에서 VERIFIED로 바뀜.
- 그리고 재정 로직에 의해 미지불 건이 있을 경우 상태를 SUSPENDED로 바꿈.
- 하지만 고객 상태는 분명 고객 도메인의 데이터.
- 그러니 고객 상태는 고객 서비스만 바꿀 수 있음.
- 재정 서비스는 고객 서비스에 API를 통해 요청을 할 수 있을 뿐.
- 하지만 이렇게 서비스가 분리되면 데이터베이스 트랜잭션이 문제가 될 수도.
- 이는 나중에 트랜잭션과 사가<sup>saga</sup>에서 다룸.

## Pattern: Move Foreign-Key Relationship to Code

- 카탈로그 서비스를 추출하기로 했다고 가정.
- 이 서비스는 음악가, 트랙, 앨범 정보를 노출하고 관리.
- 테이블은 아래와 같음.

| SKU | RRP | Album Name |
| -- | -- | -- |
| 123 | $5.99 | Born to Run |
| 687 | $17.50 | Give Blood |

- 한편, 원장(Ledger) 테이블도 있음.
- 여기엔 앨범의 모든 판매 기록이 담김.
- 그리고 Catalog ID라는 컬럼은 Albums 테이블의 SKU에 대한 외부키.

| Catalog ID | Price | Date |
| -- | -- | -- |
| 123 | $3.99 | 14/8/2018 |
| 687 | $15.50 | 15/8/2018 |

- 매월 마지막에 가장 판매량 높은 CD는 뭔지 요약하는 리포트를 만들어야 함.
- "We sold 400 copies of Bruce Springsteen's Born to Run and made $1,596" 같은 결과를 만들려면 두 테이블 모두 필요.
- 외부키로 지정되어 있으면, 외부키가 가리키는 레코드는 반드시 있음이 보장됨.
- 즉, 항상 값을 얻을 수 있음.
- 이제 이 두 테이블을 각 서비스 스키마로 이동하면, 외부키는 어떻게 될까?
- 우리는 2가지를 고려해야 함.
- 먼저, 재정 서비스는 이제 카탈로그 관련 정보를 데이터베이스 조인 없이 어떻게 얻지?
- 다음으로, Catalog ID에 대응하는 카탈로그 정보가 없다면?

### Moving the Join

- 먼저, 조인 대체 얘기.
- 당연한 얘기지만, 먼저 매출 순위를 뽑고, 목록에 나온 SKU들을 카탈로그 서비스에게 질의.
- 다만 이전과 같은 효율은 포기.
- 물론 지금과 같은 월말 리포팅에서는 문제가 안 됨.
- 하지만 자주 수행되는 코드라면 다음의 것들을 고려.
- 카탈로그 서비스 벌크 호출, 캐시, 응답지연 전후 측정, [Jaeger](https://www.jaegertracing.io/) 같은 모니터링 도구 고민, 비기능적 요구 확인 등.

### Data Consistency

**Check before deletion**

- 앨범 테이블 레코드 삭제 시, 재정 서비스에 참조 데이터가 있는지 확인.
- 하지만 이를 정확히 달성하기는 어려움.
- 예를 들어, SKU 683을 지우려고 재정 서비스에 물어봤는데 안 쓴다고 답변 옴.
- 그래서 지우려는 그 찰나, 재정 서비스에 SKU 683에 대한 참조 데이터가 생김.
- 이를 막으려면 데이터 삭제 시 재정 서비스에 잠금을 걸어야 함.
- 여기엔 여러 어려움이 뒤따름.
- 한편, 카탈로그가 재정 서비스에 질의하는 건 역 의존성.
- 이 문제는 점점 커질 수 있음.
- 이 선택지는 사용하지 않길 권장.

**Handle deletion gracefully**

- 좀 더 나은 선택지는 카탈로그 서비스가 앨범 정보가 없을 수 있음을 받아들이는 것.
- 삭제된 앨범 조회 요청이 오면 카탈로그 서비스는 `410 GONE`을 응답하고,
- 재무 서비스는 "Album Information Not Available" 식으로 표현.
- 404와 410을 구분하는 건 데이터 일관성 문제를 다룰 때 유용할 수 있음.
- 좀 더 나아간다면, 카탈로그 아이템 제거 시, 재정 서비스도 이벤트 구독 등을 통해 이를 전달받기.
- 이벤트를 받으면, 데이터를 복제해 둘지 등을 결정할 수 있음.

**Don't allow deletion**

- 데이터를 삭제하지 않는 것도 방법.
- 소프트 삭제를 하는 것.

**So how should we handle deletion?**

- 결정에는 사용자의 요구사항도 잘 고려해야 함.
- 저자는, 삭제를 하지 않으면서도 재정 서비스가 데이터 없음을 받아들이는 걸 선호.
- 레코드를 삭제하지 않기만 해도 되지 않느냐고 할 수 있음.
- 그러나 장애 복구 등으로 데이터가 이전 상태로 돌아가는 경우도 있음.
- 잘 일어나는 상황은 아니지만, 복원력을 갖고 호출 실패 상황을 고려하는 게 좋음.

### Example: Shared Static Data

- 정적인 참조 데이터(잘 안 바뀌지만 중요한)는 흥미로운 문제를 만들기도 함.
- 국가 코드가 대표적 사례이며 이를 다루는 몇 가지 선택지가 있음.

#### Pattern: duplicate static reference data

- 첫 번째 선택지는 각 서비스가 데이터 복제본을 갖는 것.
- 하지만 데이터 중복을 얘기하면 2가지 이유로 우려하곤 함.
- 먼저, 데이터 변경이 일어나면 여러 곳을 작업해야 함.
- 하지만 공식 국가 코드가 마지막으로 추가된 건 2011.
- 그래서 이건 그렇게 문제가 되지 않음.
- 더 큰 걱정거리는 데이터 비일관성.
- 재정 서비스는 새로운 국가 코드를 아는데, 재고 서비스는 모른다면?
- 데이터가 로컬에서만 사용된다면 문제가 안 됨.
- 하지만, 서비스 간 통신 데이터고 같은 값을 필요로 한다면 문제.
- 이 때는 백그라운드 프로세스로 자주 동기화를 하는 방법을 고려해 볼 수도.
- 이 선택지는 드물게 사용해야 함.
- 데이터가 방대하고 서비스간 비일관성이 허용되는 경우 등에 한함.

#### Pattern: Dedicated reference data schema

- SSOT를 원한다면 전용 스키마에 데이터를 둘 수도.
- 물론, 공유 데이터베이스가 갖는 문제들을 고려해야 함.
- 자주 바뀌지 않으니 결합도와 변경 문제는 어느 정도 상쇄.
- 그래서 참조 데이터 스키마를 공개된 인터페이스로 고려해 볼 만.
- 그럼에도 파괴적 변경은 고통스러울 것임을 기억해야.
- 이 선택지는 중복을 피하면서도, 데이터는 잘 안 바뀌므로 결합도 걱정은 줄어듦.

#### Pattern: Static reference data library

- 국가 코드는 200여개이니, enum 타입으로 정의하기 좋음.
- 이렇게 정의한 뒤 라이브러리로 제공하는 것도 방법.
- 간단하긴 하지만 아래 단점들 가짐.
- 먼저, 기술 스택이 다양할수록 라이브러리도 이를 지원해야 함.
- 다음으로, 자율적 배포가 어려움. 국가 코드를 바꿔야 하고, 모든 서비스가 즉각 반영해야 한다면, 관련된 곳을 모두 배포해야 함.
- 전형적 lock-step release.
- 충분한 시간 확보 후 사전 공지를 하는 것이 도움이 됨.
- 마지막 국가 코드가 만들어지는 데 6개월이 걸렸으니 사전 공지가 되면 어느 정도의 시간 확보 가능.
- 이 선택지도 데이터 비일관성은 피할 수 없음.
- 어떤 서비스가 어떤 버전을 갖고 있는지 확인이 쉬운 장점도 있음.

#### Pattern: Static reference data service

- 국가 코드를 제공하는 서비스 생성을 고려할 수도.
- 이를 좋다고 말하는 사람도 있지만, 너무 과하다는 입장을 더 많이 만남.
- 마이크로서비스를 만들고 관리하는 비용이 높은 곳에선 서비스 생성이 주는 이점이 상대적으로 커야할 것.
- Function-as-a-Service 플랫폼 등 비용이 매우 적은 곳에선 이점이 조금만 커도 수용할 만.
- 네트워크 지연은 국가 코드가 몇 개 되지 않음을 생각하면 고려사항은 아님.
- 클라이언트 측에서 캐시를 사용하고 이벤트 구독을 통해 변경을 반영할 수도.

#### What would I do?

- 국가 코드가 항상 모든 서비스에서 일관되어야 하는 게 아니라면 공유 라이브러리를 선호.
- 데이터가 단순하고 양도 적다면 더더욱 데이터 복제 선택지보다 우선.
- 반대의 경우라면 복제를 고려.
- 한편, 데이터 일관성이 중요하다면 전용 서비스 생성 고려.
- 일관성 중요하지만 신규 서비스 생성 비용때문에 정당성 떨어지는 경우에 한해서만 전용 스키마 고려.

## Transactions

- 데이터베이스를 쪼개면, 참조 무결성 지키기 어렵고, 응답 지연 증가하고, 리포팅 같은 작업은 복잡해짐.
- 이를 다루는 몇 가지 방법들은 이미 이야기. 하지만 트랜잭션은?
- 해결책에 앞서 일반적인 데이터베이스 트랜잭션이 제공하는 걸 간단히 살피기.

### ACID Transactions

- 트랜잭션은 결국 ACID.
- Atomicity: 트랜잭션 내의 모든 게 함께 성공하거나 함께 실패.
- Consistency: 변경이 일어나도 항상 유효하고 일관된 상태 유지.
- Isolation: 동시에 여러 트랜잭션이 서로를 간섭하지 않고 실행(트랜잭션이 완료되지 않은 중간 단계의 상태가 다른 트랜잭션에는 보이지 않음).
- Durability: 트랜잭션이 완료되면 시스템 장애에도 데이터 유실은 없음.
- 여기서 우린 주로 원자성을 다룸.
- 트랜잭션 나눌 때의 문제를 다루기 때문.

### Still ACID, but Lacking Atomicity?

- 트랜잭션은 계속 사용 가능하나 그 범위가 줄어듦.
- 여기서는 고객 등록을 사레로 들고 있음.
- 고객 등록이 완료되면,
- `PendingEnrollments` 테이블에서는 레코드를 지우고,
- `Customer` 테이블의 고객 상태 값은 `PENDING`에서 `VERIFIED`로 변경해야 함.
- 기존에는 하나의 스키마에서 하나의 트랜잭션으로 수행했음.
- 이제는 별개의 스키마에서 별개의 트랜잭션으로 수행해야 함.
- 따라서 기존의 원자성이 깨지는 상황을 받아들여야 함.
- 그리고 이런 상황을 해결하고자 분산 트랜잭션을 고려하기도.
- 일단 가장 흔한 2 단계 커밋부터 이야기.

### Two-Phase Commits

- 이 방법은 문제 해결보다는 오히려 혼란을 가중.
- 2PC는 말 그대로 2개의 단계를 가짐.
- 하나는 투표 단계(voting phase).
- 다른 하나는 커밋 단계(commit phase).
- 투표 단계에서는 중앙 코디네이터가 모든 트랜잭션 참여자에게 상태 변경에 대한 확인을 요청.
- 위 사례에서는 코디네이터가 PendingEnrollments 레코드 삭제와 Customer 상태 변경에 대한 확인을 요청.
- 모두가 동의한다면 다음 단계로 진행.
- 그렇지 않다면 전체 종료.
- 여기서 주의할 건, 투표 단계에서는 실제 상태 변경을 하지는 않고, 변경할 수 있음을 보장하기만 함.
- 그런데 어떻게 보장할 수 있을까?
- 중간에 다른 작업에 의해 레코드가 삭제될 수도 있지 않을까?
- 보장을 위해서는 그래서 레코드를 잠궈야 함.
- 투표하지 않은 워커가 있을 경우엔, 모든 참여자에게 롤백 메시지를 보내야 함.
- 그래야 잠금 등을 해제하는 작업을 할 수 있음.
- 커밋 단계에서는 실제 변경이 이뤄지고 잠금이 해제됨.
- 여기서 또 중요한 건, 모든 커밋이 동시에 일어나지는 않는다는 것.
- 워커의 응답이 느려질 수록 비일관성 가능성은 더 커짐.
- 이는 ACID의 일관성 요소 위배.
- 2PC는 결국 분산 잠금 코디네이터.
- 그리고 잠금 관리는 데드락 등의 어려움이 따름.
- 또한, 투표는 했지만 커밋 요청에 응답하지 않는 작업자가 있는 문제도 있음.
- 그 외에도 다양한 실패 모드들이 존재.
- 참여자가 늘어날수록 지연은 더 길어지고 그만큼 문제도 많아질 것.

### Distributed Transactions - Just Say No

- 지금까지의 이유로 2PC 같은 분산 트랜잭션을 사용하지 말기를 강력히 권장.
- 대안 중 하나는 데이터를 분리하지 말고 그대로 두는 것.
- ACID가 필요한 상황이라면 하나의 데이터베이스에 그대로 두기.
- 혹은 마이크로서비스 분리 시 함께 분리할 것.
- 그리고 분리가 필요하다면 이 때는 사가(saga)를 고려.

## Sagas

- Saga는 원래 단일 데이터베이스에 대한 것.
- 몇 분에서 며칠까지 걸리는 LLT(Long Lived Transaction)로 인해,
- 여러 데이터베이스 로우 또는 전체 테이블이 오랫동안 잠기는 문제가 있었고,
- 그래서 몇 개의 트랜잭션으로 나누고 독립적으로 수행하자는 것.
- 이는 여러 서비스/스키마에 걸친 트랜잭션에도 적용 가능.

### Saga Failure Modes

- 여러 트랜잭션으로 나누면, 실패를 어떻게 다룰지 고민해야 함.
- 실패가 났을 때 어떻게 복구할 건가?
- 후방 복구와 전방 복구가 가능.
- 후방 복구는 롤백이며, 이를 위해서는 보상 트랜잭션 필요.
- 전방 복구는 실패가 일어난 지점부터 재시도를 통해 처리를 이어나가는 것.
- 비즈니스에 따라 어느 하나 또는 복합적 활용 필요.

#### Saga rollbacks

- 단일 트랜잭션에서의 롤백과 사가의 롤백은 다름.
- 프로세스가 여러 작은 트랜잭션 범위들로 이뤄져 있음.
- 그래서 롤백은 보상 트랜잭션을 통해 수행.
- 디비 롤백은 마치 없었던 일처럼 됨.
- 보상 트랜잭션에서는 과거 커밋은 이미 일어난 것.
- 이미 발송한 주문 완료 이메일을 되돌릴 수 없음.
- 대신, 두 번째 메일을 보내 주문이 취소됐다고 알려야 함.
- 그래서 시멘틱 롤백이라고 부르기도 함.
