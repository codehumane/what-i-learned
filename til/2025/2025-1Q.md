# 01/11

## 카프카 핵심 가이드 2판

- [7장. 신뢰성 있는 데이터 전달](https://github.com/codehumane/what-i-learned/blob/master/book/ktdg-2e/README.md#7%EC%9E%A5-%EC%8B%A0%EB%A2%B0%EC%84%B1-%EC%9E%88%EB%8A%94-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EB%8B%AC)
- [7.1 신뢰성 보장](https://github.com/codehumane/what-i-learned/blob/master/book/ktdg-2e/README.md#71-%EC%8B%A0%EB%A2%B0%EC%84%B1-%EB%B3%B4%EC%9E%A5)
- [7.2 복제](https://github.com/codehumane/what-i-learned/blob/master/book/ktdg-2e/README.md#72-%EB%B3%B5%EC%A0%9C)

# 01/12

## 카프카 핵심 가이드 2판

- [7.3 브로커 설정](https://github.com/codehumane/what-i-learned/blob/master/book/ktdg-2e/README.md#73-%EB%B8%8C%EB%A1%9C%EC%BB%A4-%EC%84%A4%EC%A0%95)
- [7.4 신뢰성 있는 시스템에서 프로듀서 사용하기](https://github.com/codehumane/what-i-learned/blob/master/book/ktdg-2e/README.md#74-%EC%8B%A0%EB%A2%B0%EC%84%B1-%EC%9E%88%EB%8A%94-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%97%90%EC%84%9C-%ED%94%84%EB%A1%9C%EB%93%80%EC%84%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0)
- [7.5 신뢰성 있는 시스템에서 컨슈머 사용하기](https://github.com/codehumane/what-i-learned/blob/master/book/ktdg-2e/README.md#75-%EC%8B%A0%EB%A2%B0%EC%84%B1-%EC%9E%88%EB%8A%94-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%97%90%EC%84%9C-%EC%BB%A8%EC%8A%88%EB%A8%B8-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0)

# 01/19

## 카프카 핵심 가이드 2판

보기로 했던 내용 중 7장을 가장 마지막에 보기로 했었음. 마지막 정리도 끝.

- [7.6 시스템 신뢰성 검증하기](https://github.com/codehumane/what-i-learned/blob/master/book/ktdg-2e/README.md#76-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%8B%A0%EB%A2%B0%EC%84%B1-%EA%B2%80%EC%A6%9D%ED%95%98%EA%B8%B0)

# 01/26

## 모든 것은 예측 가능하다

미래는 예측할 수 있음.

- 물론, 모든건 불확실.
- 불완전하게 대략적 예측을 하는 것.
- 삶은 체스가 아닌 포커.
- 제한된 정보를 가지고 최선의 결정을 하는 것.

`P(A|B) = P(B|A)·P(A) / P(B)`

- 이 책은 베이즈 정리 이야기.
- `|` 기호는 조건부 확률을 가리킴.
- `P(A|B)`는 사건 B가 일어났다고 할 때 A가 일어날 확률.
- 그리고 흔히 드는 예시들 소개.
- 검사 정확도(민감도) != 양성 판정자가 실제 암일 확률.
- 통계적으로 유의해도 틀릴 가능성 높은 이유.
- AI 역시 베이즈적 사고의 응용.
- 지시문을 접할 때 어떤 결과를 내보일지 예측하는 것.
- 우리 뇌도 베이즈.
- 기존에 가진 믿음을 토대로 판단하고 행동.

역시나 나오는 표.

- 민감도가 0.8이고 특이도가 0.9라고 하자.
- 이 때 우리 검사 결과가 양성이라면, 실제 그 병에 걸렸을 확률은?
- 이를 판단하려면 사전 확률이 필요.
- 스스로 그 병에 걸렸을 가능성을 얼마로 생각했느냐.
- 이미 알려진 유병률을 활용할 수도.
- 그럼 아래와 같이 구할 수 있음.
- 만약 유병률이 1%라면 결과 값은 0.07.
- 800 / 10,700 = 대략 0.07.
- 매우 낮음.

| | 병 O (1,000명) | 병 X (99,000명) |
| -- | -- | -- |
| 양성 | 0.8 (참 양성: 800명) | 0.1 (거짓 양성: 9,900명) |
| 음성 | 0.2 (거짓 음성: 200명) | 0.9 (참 음성: 89,100명) |

사전 확률이 바뀌면 결과가 달라짐.

- 만약, 참 양성이 800명에서 8,000명으로 늘었다면?
- 아까 그 결과가 0.07에서 0.47로 올라감.
- 사전에 추정한 확률만 달라졌을 뿐인데.

민감도는 `P(B|A)`. 우리가 관심 있는 대상은 주로 `P(A|B)`.

- 민감도는 `P(B|A)`.
- 양성일 때 진짜일 확률은 `P(A|B)`.
- `어떤 인간이 교황일 확률은 1/80억이다`와 `교황이 인간일 확률은 1/80억이다`의 차이.
- 그리고 우리 관심사를 위해 필요한 게 사전 확률.

검사의 오류<sup>prosecutor's fallacy</sup>.

- 법률 분야에도 베이즈 사고 필요.
- DNA 검사는 높은 정밀도를 가지며 일치할 확률은 1/300만.
- 만약, 범죄 현장에서 발견한 DNA와 일치하는 사람을 발견한다면?
- 역시나 사전 확률이 있어야 함.
- 인구가 6,500만인 나라에서 무작위로 뽑아 비교한다면 20명이 일치할 것이고 따라서 범인일 확률은 0.05.
- 그런데 사전에 용의자를 10명으로 좁혀 둔 상태에서 DNA가 일치하는 사람이 있다면 사전 확률이 0.1인 것이고 거짓 양성일 확률은 1/30만.

책 기대됨.

# 01/28

## 모든 것은 예측 가능하다

### 파스칼

- 주사위를 4번 던졌을 때 6이 한 번이라도 나올 확률은?
- 그리고 주사위 한 쌍을 24번 던졌을 때 6땡이 나올 확률은?
- 카르다노의 그럴듯해 보이는 이상한 계산법 잠시 소개.
- 같은 문제를 공보라는 사람은 계산을 제대로 함.
- 4번 던지는 게임은 베팅을 해야 하고, 24번 던지는 게임은 베팅을 하면 안 됨.
- 그런데 그 이유는 몰라서 파스칼에게 물어봤다고 함.
- 결론은 `일어나지 않을 확률`을 구하기.
- 첫 번째 게임: 1 - (5/6)^4 = 0.52
- 두 번째 게임: 1 - (35/36)^24 = 0.49

### 파스칼과 페르마

- 공보는 질문을 하나 더 던짐.
- 두 사람이 운에 좌우되는 게임을 하던 중 중간에 그만둬야 할 때 판돈을 어떻게 나눠야 할까?
- 파스칼은 이 문제에 흥미를 느끼며 페르마와 편지를 주고 받았다고 함.
- 중요한 건, 앞으로 나올 수 있는 경우의 수.
- 만약, 갑과 을의 점수가 2-1이고 3점을 먼저 내야하는 상황에서는 아래와 같음.

```
                   -- (4-1: 의미 x)
        -- (3-1) -|
       |           -- (3-2: 의미 x)
(2-1) -|
       |           -- (3-2)
        -- (2-2) -|
                   -- (2-3)
```

- 2-0이든 1-1이든 위와 같은 식으로 남은 경우의 수 구하기 가능.
- 그리고 좀 더 쉽게 구하고자 파스칼 삼각형 이용할 수 있음.

<img src="https://i.namu.wiki/i/EhEA2eaEgfin4tRHvVA0t58t8yVmnRjDFwLFPXBJwbrmotnzZiRc-6cI1fP44kjohdnBaBTlho2aQTnZ5qVyBA.webp" width="400">

- 먼저 최대로 남은 판 수를 구하고,
- 남은 판 수만큼 삼각형 줄을 내려온다.
- 참고로 첫 번째 줄은 0번.
- 한 사람이 더 이겨야 하는 수 만큼의 숫자를 왼쪽부터 제거.
- 제거한 행의 총합 / 원래 행의 총합 = 이기는 확률.
- 한 번의 시행에서 나올 수 있는 결과가 2가지뿐이고, 두 결과가 나올 확률이 같다면 파스칼 삼각형 활용이 가능.
- 삼각형의 행은 사실 조합을 나타냄. 동전 7번 던지는 경우는 7행을 보면 되는데, 앞면만 계속 나올 확률은 첫 번째 숫자, 앞면이 2번 나올 확률은 두 번째 숫자, ... 식으로 대응.
- 위 확률 분포를 '이항분포'라고 함.
- 파스칼과 페르마가 주고 받은 편지는 '확률론<sup>probability theory</sup>'의 시발점.

### 큰 수의 법칙

- 큰 수의 법칙을 그 동안 조금 다른 결로 생각하고 있었던 듯.
- 일단, 잘 알다시피 베르누이는 동전을 많이 던질수록 그 결과가 '실제' 확률에 평균적으로 가까워짐을 이야기.
- 그런데, 우리의 관심사는 어떤 상태가 주어졌을 때 어떤 결과가 나올 확률을 구하는 게 아님.
- 정반대임. 전자를 표집확률<sup>sampling probability</sup>, 후자를 추론확률<sup>inferential probability</sup>이라 함.
- '표본이 이렇게 뽑혀 나왔을 때, 전체 상태가 어떻다고 추론할 수 있는가?'
- 포커에서 스트레이트 플러시가 나올 확률 계산은 간단함.
- 이 계산 대신 과학자들이 궁리하는 건, 주어진 데이터에 비추어 가설에 대해 어떤 판단을 내려야 하는가임.
- 베르누이는 항아리에서 공을 몇 개 꺼냈을 때 단지의 내용물을 어느 정도의 신뢰도로 추정할 수 있는지 알고 싶었음.
- 표본이 크수록 표본상의 비율은 실제 비율에 가까워짐.
- 여기까지는 당연할 수 있는데 좀 더 나아감.
- 표본의 크기, 실제 정답에 얼마나 가까운 추정을 원하는지, 얼마나 높은 신뢰도로 추정하려는지, 이렇게 3가지 요소를 수학적으로 정리.

> 원하는 어떤 확률값에 대해서도 표본상 비율 m/n(m은 양성 사례의 개수)과 실제 비율 p의 절대차가 그 확률로 임의의 값 ⍷ 이하가 되게 하는 관측 횟수 n을 항상 결정할 수 있다.

- 프로젝트 관리의 딜레마인 '빨리, 우수하게, 값싸게' 중 둘을 택하는 것과 유사.
- 베르누이의 생각: 확실성에는 정도가 있고, 실험을 통해 확실성을 높일 수 있음.
- 그러나 베르누이 문제는 여전히 추론확률이 아니라 표집확률.
- 표본에 나타난 공의 비율이 실제 비율과 어느 정도로 비슷하냐의 이야기.
- 단지 둘은 비슷하다는 것.
- 하지만 둘은 크게 다를 수 있음.
- 베이즈가 등장하고서 베르누이의 착각이 드러남.

# 01/30

이전에 How to Measure Anything 책에서 읽었던 [베이지안 역전](https://github.com/codehumane/what-i-learned/blob/master/book/htma-3e/README.md#the-basics-and-bayes) 다시 훑어봄.

`P(A|B) = P(A)P(B|A) / P(B)`를 대수적으로 조작하는 과정.

```
1. P(B) + P(~B) = 1
2. P(B) = P(B|A)·P(A) + P(B|~A)·P(~A)

# 위 2개를 이용한 대수적 조작.
P(A|B) = P(A)·P(B|A) / P(B)
       = P(A)·P(B|A) / ( P(B|A)·P(A) + P(B|~A)·P(~A) )
```

그래서 `P(A)`, `P(B|A)`, `P(B|~A)`를 알면 됨. 이를 민감도, 특이도 문제에 대입해 보자.

1. 우리가 관심 있는 건, 양성이 나왔을 때 실제 병에 걸렸을 확률: `P(A|B)`
2. 이미 알고 있는 민감도: `P(B|A)` = 0.8
3. 함께 알고 이는 특이도: `P(~B|~A)` = 0.9
4. 3번에 의해 `P(B|~A)` = 0.1
5. 여기서 더 필요한 건 `P(A)`이며, 이게 바로 사전확률.
6. 이미 알려진 양성률.

# 02/17

- 이펙티브 코틀린 책 오랜만에 살펴봄.
- `아이템 24. 제너릭 타입과 variance 한정자를 활용하라` 정리.

# 02/18

## 공변성

자바에서 `Collections#sort` 모습.

```java
public static <T> void sort(List<T> list, Comparator<? super T> c) {
    list.sort(c);
}
```

그리고 아래와 같은 부모/자식 클래스가 있다고 해보자.

```java
class Animal {
    String name;
    Animal(String name) {
        this.name = name;
    }
}

class Dog extends Animal {
    Dog(String name) {
        super(name);
    }
}

class Cat extends Animal {
    Cat(String name) {
        super(name);
    }
}
```

그럼 아래와 같은 것이 가능함.

```java
Comparator<Animal> animalComparator = (a1, a2) -> a1.name.compareTo(a2.name);

List<Dog> dogs = Arrays.asList(new Dog("Bulldog"), new Dog("Beagle"));
List<Cat> cats = Arrays.asList(new Cat("meow"), new Cat("meow x2"));

Collections.sort(dogs, animalComparator);
Collections.sort(cats, animalComparator);
```

추상화 된 타입으로 한 번 정의하고, 구체화된 여러 클래스들에 대해 재사용이 가능. 그리고 코틀린은 여기서 더 나아가, in과 out이 자바에 비해 더 안전하게 만들어짐.

# 02/23

[오랜만에 커서 기반 페이징 구현](https://github.com/codehumane/ntf/commit/2bc3d66f71e22ac68d3e3c05cd755845b98848b7)

```kt
SELECT n
FROM NotificationEntity n
    JOIN NotificationEventsEntity e
    ON n.id = e.notificationId
WHERE
    e.state = com.codehumane.ntf.domain.NotificationState.RESERVED
    AND (
        (:from < n.reservedAt AND n.reservedAt <= :to)
        OR (:from = n.reservedAt AND :cursor < n.id)
    )
```

# 02/26

## 베이즈주의/빈도주의 동전 사고 실험

- 구글 의사 결정 과학자 캐시 코지르코프가 든 예시라고 함.
- 본인이 본능적으로 빈도주의자인지 베이즈주의인지 알아볼 수 있는 간단한 사고 실험.
- 동전을 던지고 앞면이 나왔을 확률을 묻는다.
- 만약 50%라고 한다면 베이즈식.
- 앞면이 나왔든 뒷면이 나왔든, 확률은 자신의 주관적 믿음과 자신이 아는 정보에 관한 것.
- 반면, 0% 또는 100%라고 했다면 빈도주의.
- 객관적 사실이 존재하고 과거의 확률이 개입하는 것은 말이 안 됨.

# 02/27

## 웨이슨 선택 과제

- https://en.wikipedia.org/wiki/Wason_selection_task

> You are shown a set of four cards placed on a table, each of which has a number on one side and a color on the other. The visible faces of the cards show 3, 8, blue and red. Which card(s) must you turn over in order to test that if a card shows an even number on one face, then its opposite face is blue?

> 테이블에 4개의 카드가 있다. 각 카드는 한 쪽 면에는 숫자가, 다른 한 쪽 면에는 색깔이 표시 되어 있음. 지금 보이는 건 3, 8, 파랑, 빨강. 만약, 한 쪽이 짝수면 반대편은 파랑인지를 확인하려면, 어떤 카드를 뒤짚어야 하는가?

- 사실은 함정 문제이고, 추상적 상황이 아닌 우리 현실과 더 관련 있는 선택의 상황에서는 올바르게 선택한다는, 매드슨이라는 사람의 주장 속에 나온 인용.
- 매드슨 얘기도 너무 재밌고(맥주, 사람 이야기인데 정말로 생각할 필요 없이 맞추기 쉬웠음), 위 사례도 재밌어서 기록.
- 개인적으로는 직업 때문인지 웨이슨 문제도 간단했음.
