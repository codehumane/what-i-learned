
2024년 시작.

# 01/01

## 우리는 왜 숫자에 속을까

### 8장. 인공지능은 모든 걸 알고 있다

독일 내무부는 아래 2가지 숫자 때문에, 안면 인식 시스템에 열광하게 됨.

1. 적중률: 80
2. 오경보율: 0.1

위험 인물 100명 중 80명을 올바르게 인식하고, 1,000명 중 1명만 위험인물로 잘못 간주한다는 것. 이렇게만 보면 매우 우수한 시스템처럼 보임.

그런데 일단 사소한 문제 3가지가 있음.

1. 일단, 테스트에 사용된 시스템은 3개인데, 세 시스템 중 하나라도 위험인물을 맞추면 적중률에 포함함.
2. 또한, 테스트는 총 2회에 걸쳐 이뤄졌는데, 2회차에서는 고화질 카메라로 찍은 사진을 사용해 적중률이 훨씬 높아짐.
3. 그리고, 수집한 모든 데이터가 아닌 일부 데이터를 취사선택해 적중률을 계산하고, 선택의 기준도 명시하지 않음.

그리고 근본적 문제는 오경보에 있음.

![안면 인식 시스템 감시 빈도 수형도](./안면인식시스템_감시빈도수형도.png)

빈도 수형도를 그려 보면 문제가 드러남.

1. 역 이용자가 1,200만명이라고 할 때, 1.2만명이 수배자로 잘못 지정(오경보율 0.1퍼센트).
2. 카메라가 위험인물로 인식한 사람이 정말로 위험할 확률은 0.7퍼센트(= 80 / 12,080).
3. 즉, 99.3%는 잘못된 경보인 가짜 양성.
4. 하루에도 1.2만 번의 가짜 알림이 울림. 엄청난 비용.

가짜 양성 비율과 양성 예측도를 구분하지 못하면, 0.1%라는 오경보율을 보고 99.9%의 경우 시스템이 올바른 분류를 한다고 착각하게 됨.

1. 가짜 양성 비율: 위험인물이 아닌 사람 중 얼마나 많은 사람이 위험인물로 잘못 분류되나? -> 0.1%
2. 양성 예측도: 시스템이 위험인물로 분류한 사람이 실제로 위험인물일 확률은 얼마나 높은가? -> 1%
